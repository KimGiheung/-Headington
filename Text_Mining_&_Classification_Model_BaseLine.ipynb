{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5UBFHXkFQ22g0RBZFUqRS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KimGiheung/MamMaMap/blob/Giheung-Ai/Text_Mining_%26_Classification_Model_BaseLine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHdhx5zwGREV"
      },
      "outputs": [],
      "source": [
        "#Text Mining & Classification Model BaseLine\n",
        "\n",
        "#Library & Data import\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "df = pd.read_csv('/content/nursing_room_reviews_kr.csv', encoding='utf-8')\n",
        "# 정규 표현식 함수 정의\n",
        "\n",
        "import re\n",
        "\n",
        "def apply_regular_expression(text):\n",
        "    hangul = re.compile('[^ ㄱ-ㅣ 가-힣]')  # 한글 추출 규칙: 띄어 쓰기(1 개)를 포함한 한글\n",
        "    result = hangul.sub('', text)  # 위에 설정한 \"hangul\"규칙을 \"text\"에 적용(.sub)시킴\n",
        "    return result\n",
        "#특수문자 제거\n",
        "apply_regular_expression(df['text'][0])\n",
        "from konlpy.tag import Okt\n",
        "from collections import Counter\n",
        "okt = Okt()  # 명사 형태소 추출 함수\n",
        "nouns = okt.nouns(apply_regular_expression(df['text'][0]))\n",
        "nouns\n",
        "# 말뭉치 생성\n",
        "corpus = \"\".join(df['text'].tolist())\n",
        "corpus\n",
        "# 정규 표현식 적용\n",
        "apply_regular_expression(corpus)\n",
        "# 전체 말뭉치(corpus)에서 명사 형태소 추출\n",
        "nouns = okt.nouns(apply_regular_expression(corpus))\n",
        "print(nouns)\n",
        "counter = Counter(nouns)\n",
        "counter.most_common(10)\n",
        "#한글자 명사 제거\n",
        "available_counter = Counter({x: counter[x] for x in counter if len(x) > 1})\n",
        "available_counter.most_common(10)\n",
        "#한국어 불용어 사전\n",
        "stopwords = pd.read_csv(\"https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/korean_stopwords.txt\").values.tolist()\n",
        "stopwords[:10]\n",
        "#데이터셋에 특화된 불용어 처리 ex)수유실\n",
        "nursing_room_stopwords = ['수유실', '부산']\n",
        "for word in nursing_room_stopwords:\n",
        "    stopwords.append(word)\n",
        "#워드 카운트\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "def text_cleaning(text):\n",
        "    hangul = re.compile('[^ ㄱ-ㅣ 가-힣]')  # 정규 표현식 처리\n",
        "    result = hangul.sub('', text)\n",
        "    okt = Okt()  # 형태소 추출\n",
        "    nouns = okt.nouns(result)\n",
        "    nouns = [x for x in nouns if len(x) > 1]  # 한글자 키워드 제거\n",
        "    nouns = [x for x in nouns if x not in stopwords]  # 불용어 제거\n",
        "    return nouns\n",
        "\n",
        "vect = CountVectorizer(tokenizer = lambda x: text_cleaning(x))\n",
        "bow_vect = vect.fit_transform(df['text'].tolist())\n",
        "word_list = vect.get_feature_names()\n",
        "count_list = bow_vect.toarray().sum(axis=0)\n",
        "# 단어 리스트\n",
        "word_list\n",
        "# 각 단어가 전체 리뷰중에 등장한 총 횟수\n",
        "count_list\n",
        "# 각 단어의 리뷰별 등장 횟수\n",
        "bow_vect.toarray()\n",
        "# \"단어\" - \"총 등장 횟수\" Matching\n",
        "\n",
        "word_count_dict = dict(zip(word_list, count_list))\n",
        "word_count_dict\n",
        "def rating_to_label(rating):\n",
        "    if rating > 3:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "df['y'] = df['rating'].apply(lambda x: rating_to_label(x))\n",
        "\n",
        "#분류 모델 베이스라인\n",
        "\n",
        "# 필요한 라이브러리 import\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 데이터 준비\n",
        "X = df['text']  # 텍스트 데이터\n",
        "y = df['y']  # 레이블 (긍정: 1, 부정: 0)\n",
        "\n",
        "# 훈련 데이터와 테스트 데이터로 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 텍스트 데이터 전처리 함수 (앞서 구현한 것과 비슷하게)\n",
        "def text_preprocessing(text):\n",
        "    # 원하는 전처리 작업을 수행\n",
        "    text = apply_regular_expression(text)\n",
        "    text = text_cleaning(text)\n",
        "    return text\n",
        "\n",
        "X_train = X_train.apply(text_preprocessing)\n",
        "X_test = X_test.apply(text_preprocessing)\n",
        "\n",
        "# 텍스트 데이터를 벡터로 변환 (위에서 사용한 CountVectorizer 사용)\n",
        "vect = CountVectorizer(tokenizer=lambda x: x)\n",
        "X_train_bow = vect.fit_transform(X_train)\n",
        "X_test_bow = vect.transform(X_test)\n",
        "\n",
        "# 분류 모델 학습\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train_bow, y_train)\n",
        "\n",
        "# 예측\n",
        "y_pred = model.predict(X_test_bow)\n",
        "\n",
        "# 정확도 평가\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"모델 정확도: {accuracy}\")\n",
        "\n",
        "# 예측 함수 (텍스트를 입력으로 받아 긍정 또는 부정 예측)\n",
        "def predict_sentiment(text):\n",
        "    preprocessed_text = text_preprocessing(text)\n",
        "    text_vector = vect.transform([preprocessed_text])\n",
        "    prediction = model.predict(text_vector)[0]\n",
        "    if prediction == 1:\n",
        "        return \"긍정적인 리뷰\"\n",
        "    else:\n",
        "        return \"부정적인 리뷰\"\n",
        "\n",
        "# 예측 테스트\n",
        "sample_text = \"이 수유실은 정말 편리하고 깨끗해요!\"\n",
        "result = predict_sentiment(sample_text)\n",
        "print(f\"텍스트 감정: {result}\")"
      ]
    }
  ]
}